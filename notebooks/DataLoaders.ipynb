{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataLoaders.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPRk869hHrh6P+ztrvNV7lm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ssvfTClBCPLa"},"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVaaig8Cw6t"},"source":["#Standard imports\n","import numpy as np\n","import torch\n","from torch.utils.data.dataset import Dataset\n","from torch.utils.data import DataLoader\n","\n","import cv2\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juS9Jh7JC9Id"},"source":["#Dataset object used to load the images\n","class ObjectsDataset(Dataset):\n","  def __init__(self, frames, labels_index, rgb=True):\n","    #Store the frame paths and the corresponding labels\n","    self.labels = labels_index\n","    self.frames = frames\n","    self.rgb = rgb\n","    \n","  def __len__(self):\n","    return len(self.frames)\n","    \n","  def __getitem__(self, index):\n","    #Access the current frame and label\n","    frame_path = self.frames[index]\n","    label_index = self.labels[index]\n","    \n","    #Load images and turn to tensors\n","    if self.rgb:\n","        image = cv2.imread(frame_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = image/ 255.0\n","\n","        image=torch.from_numpy(image.astype('float32')).permute(2, 0, 1)\n","    else:\n","        image = cv2.imread(frame_path, 0)\n","        image = image/ 255.0\n","        image=torch.from_numpy(image.astype('float32')).permute(0, 1)\n","\n","    #Return frame along with label\n","    label=torch.from_numpy(np.asarray(label_index).astype('long'))\n","    return (image, label) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0X-cPG2ojp7"},"source":["def get_dataloader(image_type='cortical', personal=True, skip=8, batch_size=8, shuffle=True, rgb=True):\n","    \"\"\"\n","    Function used to get the dataset dataloader\n","\n","    Parameters\n","    ----------\n","    image_type: str\n","        Used to determine the image type. Needs to be one of 'original', 'original_corticalimages', \n","        'original_fixationcrop', or 'original_retinalimages'\n","    personal: bool\n","        Used to determine which dataset to use. 'True' will use my personal dataset, while any other will default to\n","        Alvaro's dataset\n","    skip: int\n","        Used to trim the dataset. The resulting length of the dataset is the full dataset length divided by skip\n","        For example, skip=8 will skip every 8 frames and save the 9th.\n","    batch_size: int\n","        The batch size of the final dataloader\n","    shuffle: bool\n","        Determine the dataloader will shuffle or not\n","    rgb: bool\n","        Determine whether to use RGB images or grayscale images\n","    \"\"\"\n","    \n","    if personal:\n","        #Path to my dataset\n","        train = '/content/drive/My Drive/Personal Dataset/Frames/train/'\n","        test = '/content/drive/My Drive/Personal Dataset/Frames/test/'\n","        classes = ['Background', 'Charger', 'Coin', 'Gargoyle', 'Glasses', \n","                   'Jellyfish', 'Key', 'Laptop', 'Pens', 'Remote', 'Wallet']\n","    else:\n","        #Path to Alvaro's dataset\n","        train = '/content/drive/My Drive/RODframes2/RODframes/train/'\n","        test = '/content/drive/My Drive/RODframes2/RODframes/test/'\n","        classes = ['bag','beer','book','case','coffee','cup','deodorant','eraser',\n","                   'hole','mouse','mug','sleep','speaker','spray','stapler','tape',\n","                   'tea','tissues','umbrella','watch']\n","\n","    #Store the frames and labels here\n","    train_frames = []\n","    train_labels = []\n","    test_frames = []\n","    test_labels = []\n","    #Iterate over the classes\n","    for i, obj in enumerate(classes):\n","        #Determine the path\n","        if personal:\n","            obj_train = os.path.join(train, obj, image_type)\n","            obj_test = os.path.join(test, obj, image_type)\n","        else:\n","            obj_train = os.path.join(train, obj, 'light', image_type)\n","            obj_test = os.path.join(test, obj, 'light', image_type)\n","        #Get the absolute paths of the frames\n","        obj_frame_paths = [os.path.join(obj_train, frame) for frame in os.listdir(obj_train)[::skip]]\n","        #Save the current class's frame path and corresponding labels\n","        train_frames += obj_frame_paths\n","        train_labels += [i]*len(obj_frame_paths)\n","\n","        #Do the same for the test set\n","        obj_frame_paths = [os.path.join(obj_test, frame) for frame in os.listdir(obj_test)[::skip]]\n","        test_frames += obj_frame_paths\n","        test_labels += [i]*len(obj_frame_paths)\n","\n","    #Load the Dataset \n","    train_dataset = ObjectsDataset(train_frames, train_labels, rgb)\n","    test_dataset = ObjectsDataset(test_frames, test_labels, rgb)\n","\n","    #Turn to Dataloaders and return\n","    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = shuffle, \n","                                              num_workers = 0, drop_last=True)\n","    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = shuffle, \n","                                              num_workers = 0, drop_last=True)\n","    return {'train': train_loader, 'test': test_loader}\n","    \n"],"execution_count":null,"outputs":[]}]}