{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataLoaders.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIovH+OB0TkIOev54SzQLn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ssvfTClBCPLa"},"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVaaig8Cw6t"},"source":["import torch\n","import numpy as np\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision\n","from torch.utils.data.dataset import Dataset, Subset\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import cv2\n","import copy\n","\n","\n","from torch._utils import _accumulate\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juS9Jh7JC9Id"},"source":["class ObjectsDataset(Dataset):\n","  \n","  def __init__(self, dataset_dir, frames, labels_index, image_type, rgb=True):\n","    # image_type can be original, gray image or color-opponency. It is expected \n","    # that images with these types are already available - gotten through preprocessing offline. \n","    \n","    self.labels = labels_index\n","    self.dataset_dir = dataset_dir\n","    self.transforms = transforms\n","    self.image_type = image_type\n","    self.frames = frames\n","    #self.labels_names = labels_names\n","    self.dataset_dir = dataset_dir\n","    self.rgb = rgb\n","    \n","  def __len__(self):\n","    return len(self.frames)\n","    \n","  def __getitem__(self, index):\n","    frame_path = self.frames[index]\n","    label_index = self.labels[index]\n","    #plant_name = self.labels_names[label_index]\n","    \n","    if self.rgb:\n","        image = cv2.imread(frame_path)\n","        image = image/ 255.0\n","        image=torch.from_numpy(image.astype('float32')).permute(2, 0, 1)\n","    else:\n","        image = cv2.imread(frame_path, 0)\n","        image = image/ 255.0\n","        image=torch.from_numpy(image.astype('float32')).permute(0, 1)\n","    \n","    #image = cv2.resize(image, (1080, 720))  \n","    \n","    \n","    \n","    label=torch.from_numpy(np.asarray(label_index).astype('long'))\n","        \n","    return (image, label) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZ50vrAmDPh6"},"source":["import os\n","import re\n","\n","def natural_key(string_):\n","    \"\"\"See http://www.codinghorror.com/blog/archives/001018.html\"\"\"\n","    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n","\n","def get_dataloader(image_type='original', skip=6, batch_size=64, shuffle=True, rgb=True):\n","    classes = ['bag','beer','book','case','coffee','cup','deodorant','eraser',\n","               'hole','mouse','mug','sleep','speaker','spray','stapler','tape',\n","               'tea','tissues','umbrella','watch']\n","    \n","    root_path = '/content/drive/My Drive/RODframes2/RODframes/'\n","    model_path = '/content/drive/My Drive/Colab Notebooks/RetinaSmartCamera/models/'\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(device)\n","\n","    #image_path = os.path.join(root_path)\n","    train_path = os.path.join(root_path, 'train/')\n","    test_path = os.path.join(root_path, 'test/')\n","    \n","    master_frames = []\n","    master_labels = []\n","    \n","    frames = []\n","    labels = []\n","\n","    errors = []\n","    min_count = 7200\n","    for index, obj in enumerate(classes):\n","        print('Iterating over {}'.format(obj))\n","        try:\n","            object_frames = []\n","            labels_index = []\n","\n","            object_path = os.path.join(train_path, obj+'/light/'+image_type+'/')\n","            count_index = 0\n","\n","            for frame_index, frame in enumerate(os.listdir(object_path)):\n","                if count_index%skip == 0:\n","                    frame_path = os.path.join(object_path, frame)\n","                    object_frames.append(frame_path)\n","                    labels_index.append(frame_index)\n","                count_index += 1\n","            \n","            if len(object_frames) < min_count:\n","                min_count = len(object_frames)\n","            sorted_object_frames = sorted(object_frames, key=natural_key)\n","            master_frames.append(sorted_object_frames)\n","            master_labels.append(labels_index)\n","            print('Number of images for class ',obj, ': ', len(sorted_object_frames))\n","        \n","        except OSError as err:\n","            print(\"OS error for object {}: {}\".format(obj, err))\n","            errors.append((index, obj))\n","            continue\n","    \n","    print(errors)\n","    \n","    for i in range(0, min_count):\n","        for object_index in range(len(classes)-1):\n","            frames.append(master_frames[object_index][i])\n","            labels.append(master_labels[object_index][i])\n","    print(len(frames))\n","    dataset = ObjectsDataset(root_path, frames, labels, image_type, rgb)\n","\n","    train_size = int (0.8 * len(dataset))\n","    validation_size = int(0.15 * len(dataset))\n","    test_size = len(dataset) - train_size - validation_size\n","    train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size],\n","                                                                                    generator=torch.Generator().manual_seed(42))\n","    print(len(train_dataset))\n","    dataset_dict = {'train' : train_dataset, 'validation' : validation_dataset, 'test' : test_dataset}\n","\n","    dataloader = {x : torch.utils.data.DataLoader(dataset_dict[x], batch_size = batch_size, shuffle = shuffle, \n","                                                  num_workers = 0, drop_last=True) for x in ['train', 'test', 'validation']}\n","    \n","    dataset_sizes = {x: len(dataset_dict[x]) for x in ['train', 'test', 'validation']}\n","    print('Dataset size is ', dataset_sizes)\n","\n","    return dataloader\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHNKXdNCbTaq"},"source":[""],"execution_count":null,"outputs":[]}]}