{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataLoaders.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCDsUPaYAA3T9H961dtN23"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ssvfTClBCPLa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610470188285,"user_tz":-60,"elapsed":606,"user":{"displayName":"Nicholas Sperry","photoUrl":"","userId":"17478191746282896441"}},"outputId":"163e42bf-d7f9-4d64-9582-6195a86e9265"},"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KlVaaig8Cw6t"},"source":["import torch\n","import numpy as np\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision\n","from torch.utils.data.dataset import Dataset, Subset\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import cv2\n","import copy\n","\n","\n","from torch._utils import _accumulate\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juS9Jh7JC9Id"},"source":["class ObjectsDataset(Dataset):\n","  \n","  def __init__(self, dataset_dir, frames, labels_index, label_name, image_type, rgb=True):\n","    # image_type can be original, gray image or color-opponency. It is expected \n","    # that images with these types are already available - gotten through preprocessing offline. \n","    \n","    self.labels = labels_index\n","    self.dataset_dir = dataset_dir\n","    self.transforms = transforms\n","    self.image_type = image_type\n","    self.frames = frames\n","    self.label_name = label_name\n","    self.dataset_dir = dataset_dir\n","    self.rgb = rgb\n","    \n","  def __len__(self):\n","    return len(self.frames)\n","    \n","  def __getitem__(self, index):\n","    frame_path = self.frames[index]\n","    label_index = self.labels[index]\n","    #object_name = self.label_name[index]\n","    \n","    if self.rgb:\n","        image = cv2.imread(frame_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = image/ 255.0\n","\n","        image=torch.from_numpy(image.astype('float32')).permute(2, 0, 1)\n","    else:\n","        image = cv2.imread(frame_path, 0)\n","        image = image/ 255.0\n","        image=torch.from_numpy(image.astype('float32')).permute(0, 1)\n","    \n","    #image = cv2.resize(image, (1080, 720))  \n","    \n","    \n","    \n","    label=torch.from_numpy(np.asarray(label_index).astype('long'))\n","        \n","    return (image, label) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZ50vrAmDPh6"},"source":["import os\n","import re\n","\n","def natural_key(string_):\n","    \"\"\"See http://www.codinghorror.com/blog/archives/001018.html\"\"\"\n","    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n","\n","def get_frames(train_test_path, obj, image_type, skip, min_count):\n","        object_frames = []\n","        labels_index = []\n","\n","        #Alvaro's Dataste\n","        if 'RODframes' in train_test_path:\n","            object_path = os.path.join(train_test_path, obj+'/light/'+image_type+'/')\n","        #My dataset\n","        else:\n","            object_path = os.path.join(train_test_path, obj+'/'+image_type+'/')\n","        count_index = 0\n","\n","        for frame_index, frame in enumerate(os.listdir(object_path)):\n","            if count_index%skip == 0:\n","                frame_path = os.path.join(object_path, frame)\n","                object_frames.append(frame_path)\n","                labels_index.append(frame_index)\n","            count_index += 1\n","            \n","        if len(object_frames) < min_count:\n","            min_count = len(object_frames)\n","        sorted_object_frames = sorted(object_frames, key=natural_key)\n","        print('Number of images for class ',obj, ': ', len(sorted_object_frames))\n","\n","        return sorted_object_frames, labels_index, min_count\n","\n","def get_dataloader(image_type='original', dataset_type='Alvaro', get_test=False, skip=6, batch_size=64, shuffle=True, rgb=True, ignore=[]):\n","\n","    if dataset_type=='Alvaro':\n","        root_path = '/content/drive/My Drive/RODframes2/RODframes/'\n","        classes = ['bag','beer','book','case','coffee','cup','deodorant','eraser',\n","                   'hole','mouse','mug','sleep','speaker','spray','stapler','tape',\n","                   'tea','tissues','umbrella','watch']\n","    else:\n","        root_path = '/content/drive/My Drive/Personal Dataset/Frames/'\n","        classes = ['Background', 'Charger', 'Coin', 'Earphones', 'Gargoyle', 'Glasses', 'Jellyfish',\n","                   'Key', 'Laptop', 'Pens', 'Remote', 'Wallet']\n","        \n","    for name in ignore:\n","        classes.remove(name)\n","    \n","    \n","    model_path = '/content/drive/My Drive/Colab Notebooks/RetinaSmartCamera/models/'\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(device)\n","\n","    #image_path = os.path.join(root_path)\n","    train_path = os.path.join(root_path, 'train/')\n","    test_path = os.path.join(root_path, 'test/')\n","    \n","    master_frames = []\n","    master_labels = []\n","    master_frames_test = []\n","    master_labels_test = []\n","    \n","    frames = []\n","    labels = []\n","    frames_test = []\n","    labels_test = []\n","\n","    errors = []\n","    min_count = 7200\n","    min_count_test = 7200\n","    \n","    for index, obj in enumerate(classes):\n","        print('Iterating over {}'.format(obj))\n","        try:\n","            frames_list, labels_list, min_count = get_frames(train_path, obj, image_type, skip, min_count)\n","            master_frames.append(frames_list)\n","            master_labels.append(labels_list)\n","            if get_test:\n","                frames_list, labels_list, min_count_test = get_frames(test_path, obj, image_type, skip, min_count_test)\n","                master_frames_test.append(frames_list)\n","                master_labels_test.append(labels_list)\n","               \n","        except OSError as err:\n","            print(\"OS error for object {}: {}\".format(obj, err))\n","            errors.append((index, obj))\n","            continue\n","    \n","\n","\n","    print(errors)\n","    print(len(classes))\n","    for i in range(0, min_count):\n","        for object_index in range(len(classes)):\n","            frames.append(master_frames[object_index][i])\n","            #labels.append(master_labels[object_index][i])\n","            labels.append(object_index)\n","            #print(object_index)\n","    \n","    print(len(frames))\n","    \n","    dataset = ObjectsDataset(root_path, frames, labels, classes, image_type, rgb)\n","    \n","    train_dataset = dataset\n","    #train_size = int (0.8 * len(dataset))\n","    #validation_size = int ( (0.2 if get_test else 0.15) * len(dataset))\n","    #test_size = len(dataset) - train_size - validation_size\n","    #train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size],\n","                                                                                    #generator=torch.Generator().manual_seed(42))\n","    if get_test:\n","        for i in range(0, min_count_test):\n","            for object_index in range(len(classes)):\n","                frames_test.append(master_frames_test[object_index][i])\n","                labels_test.append(object_index)\n","        \n","        test_dataset = ObjectsDataset(root_path, frames_test, labels_test, classes, image_type, rgb)\n","        test_size = int (0.7*len(test_dataset))\n","        validation_size = len(test_dataset) - test_size\n","        test_dataset, validation_dataset = torch.utils.data.random_split(test_dataset,[test_size, validation_size],\n","                                                                         generator=torch.Generator().manual_seed(42))\n","\n","    dataset_dict = {'train' : train_dataset, 'validation' : validation_dataset, 'test' : test_dataset}\n","\n","    dataloader = {x : torch.utils.data.DataLoader(dataset_dict[x], batch_size = batch_size, shuffle = shuffle, \n","                                                  num_workers = 0, drop_last=True) for x in ['train', 'test', 'validation']}\n","    \n","    dataset_sizes = {x: len(dataset_dict[x]) for x in ['train', 'test', 'validation']}\n","    print('Dataset size is ', dataset_sizes)\n","\n","    \"\"\"if get_test:\n","        for i in range(0, min_count_test):\n","            for object_index in range(len(classes)):\n","                frames_test.append(master_frames_test[object_index][i])\n","                labels_test.append(master_labels_test[object_index][i])\n","        \n","        test_dataset = ObjectsDataset(root_path, frames_test, labels_test, classes, image_type, rgb)\n","\n","        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, \n","                                                      num_workers=0, drop_last=True)\n","        print('Test Dataset size is ', len(test_dataset))\n","        return dataloader, test_dataloader\"\"\"\n","\n","    return dataloader\n","    "],"execution_count":null,"outputs":[]}]}