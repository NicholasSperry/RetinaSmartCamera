{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19017,
     "status": "ok",
     "timestamp": 1617442843608,
     "user": {
      "displayName": "Nicholas Sperry",
      "photoUrl": "",
      "userId": "17478191746282896441"
     },
     "user_tz": -120
    },
    "id": "mwbYfvHh2Loz",
    "outputId": "996ec863-8b7f-489a-9344-cd30abbd66b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23118,
     "status": "ok",
     "timestamp": 1617442847726,
     "user": {
      "displayName": "Nicholas Sperry",
      "photoUrl": "",
      "userId": "17478191746282896441"
     },
     "user_tz": -120
    },
    "id": "ijYTq5_s2gA6",
    "outputId": "cdf290bc-4d05-4510-f9ff-b9c8ee9f28f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting import-ipynb\n",
      "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
      "Building wheels for collected packages: import-ipynb\n",
      "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp37-none-any.whl size=2976 sha256=22b60f0178fbdda83b2375fecd065dcc365d8a38e77f6a7891d45d83d6a12406\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
      "Successfully built import-ipynb\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.3\n",
      "/content/drive/My Drive/Colab Notebooks/RetinaSmartCamera/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pip install import-ipynb\n",
    "%cd /content/drive/My\\ Drive/Colab\\ Notebooks/RetinaSmartCamera/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8357,
     "status": "ok",
     "timestamp": 1617442861322,
     "user": {
      "displayName": "Nicholas Sperry",
      "photoUrl": "",
      "userId": "17478191746282896441"
     },
     "user_tz": -120
    },
    "id": "nb-nnP7I2jCH",
    "outputId": "2578d448-1059-47ef-bdd7-586bc165c96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from RetinaUtils.ipynb\n",
      "importing Jupyter notebook from DataLoaders.ipynb\n"
     ]
    }
   ],
   "source": [
    "#Import the Retina and Dataloader notebooks\n",
    "import import_ipynb\n",
    "import RetinaUtils as ru\n",
    "\n",
    "import DataLoaders\n",
    "\n",
    "#Standard imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47hrZL706kHJ"
   },
   "outputs": [],
   "source": [
    "#Our Encoder module\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        #Encode a 1x8,192 retinal vector down\n",
    "        #to a 1x1,448\n",
    "        self.enc1 = nn.Linear(8192, 7000)\n",
    "        self.enc2 = nn.Linear(6000, 4096)\n",
    "        self.enc3 = nn.Linear(4096, 2896)\n",
    "        self.enc4 = nn.Linear(2896, 2048)\n",
    "        self.enc5 = nn.Linear(2048, 1448)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        x = F.relu(self.enc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helSJ58Y60fO"
   },
   "outputs": [],
   "source": [
    "#Our Decoder module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        #Decode a 1x1,448 vector back up to a \n",
    "        #1x8,192 retinal vector\n",
    "        self.dec1 = nn.Linear(1448, 2048)\n",
    "        self.dec2 = nn.Linear(2048, 2896)\n",
    "        self.dec3 = nn.Linear(2896, 4096)\n",
    "        self.dec4 = nn.Linear(4096, 6000)\n",
    "        self.dec5 = nn.Linear(7000, 8192)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x))\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7OBj92O27GPK"
   },
   "outputs": [],
   "source": [
    "#Combine the Encoder and Decoder modules\n",
    "#This was done to easily split them back up\n",
    "class NeuralBottleneck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralBottleneck, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    def forward(self, x):\n",
    "        #First encode the vector: 1x8,192->1x1,448\n",
    "        x = self.encoder(x)\n",
    "        #Then decode the vector: 1x1,448->1x8,192\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4Hao31DN2h0"
   },
   "outputs": [],
   "source": [
    "#Import the images. In this case we are using Alvaro's dataset\n",
    "from DataLoaders import get_dataloader\n",
    "dataloader = get_dataloader(image_type='original', personal=False skip=10, batch_size=8, shuffle=True, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1617442893930,
     "user": {
      "displayName": "Nicholas Sperry",
      "photoUrl": "",
      "userId": "17478191746282896441"
     },
     "user_tz": -120
    },
    "id": "FqltDKIp6dZB"
   },
   "outputs": [],
   "source": [
    "#Load Ozimek's 8,192 node retina, and enable GPU acceleration\n",
    "R = ru.Retina(gpu=True)\n",
    "data_dir = '../retina_data/retinas/'\n",
    "R.loadLoc(data_dir+'ret8k_loc.pkl')\n",
    "R.loadCoeff(data_dir+'ret8k_coeff.pkl')\n",
    "R.prepare((1080,1920), (540.0,960.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzbKuOMKWrm3"
   },
   "outputs": [],
   "source": [
    "#Sampling each image using Pytorch's Dataloader class is too slow,\n",
    "#so this function pre-loads every retinal vector so that we only sample once\n",
    "def load_img_vectors(dataloader):\n",
    "    vectors = []\n",
    "    j=0\n",
    "    #Go over every image\n",
    "    for data in iter(dataloader['train']):\n",
    "        #Give update\n",
    "        if j%50==0:\n",
    "            print(\"Iteration {}\".format(j))\n",
    "        j += 1\n",
    "\n",
    "        #Get images in correct shape for Ozimek's retina, and set fixation\n",
    "        images, _ = data\n",
    "        images = images.view(8, images.shape[1],images.shape[2])\n",
    "        x = images.shape[2]/2\n",
    "        y = images.shape[1]/2\n",
    "        fixation = (y,x)\n",
    "\n",
    "        #Here we store the retinal vector batches\n",
    "        vector_batches = np.ones((8, 1, 8192))\n",
    "        for i in range(0, 8):\n",
    "            #Sample each image in a batch and save them\n",
    "            V = R.sample(images[i]*255, fixation)\n",
    "            vector_batches[i,:] = V/255.0\n",
    "            \n",
    "        vectors.append(vector_batches)\n",
    "    #Return a tensor of the retinal vectors\n",
    "    vectors = torch.as_tensor(vectors)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1027732,
     "status": "ok",
     "timestamp": 1616858249812,
     "user": {
      "displayName": "Nicholas Sperry",
      "photoUrl": "",
      "userId": "17478191746282896441"
     },
     "user_tz": -60
    },
    "id": "1WF9TVLRYN2F",
    "outputId": "67d3a28a-d2ec-4b7c-807b-f89e175223fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 50\n",
      "Iteration 100\n",
      "Iteration 150\n",
      "1027.0007064342499\n"
     ]
    }
   ],
   "source": [
    "#Load the retinal vectors\n",
    "import time\n",
    "start = time.time()\n",
    "vectors = load_img_vectors(dataloader)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mK_PD9l9kNCx"
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "def train(model, criterion, optimiser, dataset):\n",
    "    train_loss = 0\n",
    "    i=0\n",
    "    #iterate through the dataset\n",
    "    for i, retinal_vector in enumerate(dataset):\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f'Iteration {i}')\n",
    "        retinal_vector = retinal_vector.float().to(device)\n",
    "        \n",
    "        optimiser.zero_grad()   \n",
    "        outputs = model(retinal_vector)\n",
    "        #Compare original retinal vector to the reconstructions.\n",
    "        loss = criterion(outputs, retinal_vector)   \n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        #Update running loss\n",
    "        train_loss += loss.item()*retinal_vector.size(0)\n",
    "    #Return average loss\n",
    "    return train_loss/len(dataset)\n",
    "\n",
    "def run(model, criterion, optimiser, dataloader, model_name, epochs=5):\n",
    "    model.to(device)\n",
    "    avg_train_loss = []\n",
    "    #Train the model and save the average loss per epoch\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'----------Epoch {epoch}----------')\n",
    "        train_loss = train(model, criterion, optimiser, dataloader)\n",
    "        avg_train_loss.append(train_loss)\n",
    "        print(f'Train loss: {train_loss}')\n",
    "    \n",
    "    #Plot the loss and save the figure\n",
    "    plt.plot(range(1,epochs+1), avg_train_loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.xticks([0,10,20,30,40,50,60,70,80,90,100])\n",
    "    plt.savefig(model_name+'.eps')\n",
    "    \n",
    "    #Save the final model\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            }, '/content/drive/My Drive/Colab Notebooks/RetinaSmartCamera/models/'+model_name+'.pt')\n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1102655,
     "status": "ok",
     "timestamp": 1616865540435,
     "user": {
      "displayName": "Nicholas Sperry",
      "photoUrl": "",
      "userId": "17478191746282896441"
     },
     "user_tz": -60
    },
    "id": "RVeCXVlEpaOK",
    "outputId": "1a8a6344-7365-4733-9ad7-d5fea1489593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Epoch 1----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.15624342136776326\n",
      "----------Epoch 2----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.05731752044377253\n",
      "----------Epoch 3----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.041290107797639274\n",
      "----------Epoch 4----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.035853457685137535\n",
      "----------Epoch 5----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.033737658561428185\n",
      "----------Epoch 6----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.027280452574804884\n",
      "----------Epoch 7----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.026744536373802683\n",
      "----------Epoch 8----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.024012939207563082\n",
      "----------Epoch 9----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.022208204756961347\n",
      "----------Epoch 10----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.023196253983169487\n",
      "----------Epoch 11----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.022682404582455906\n",
      "----------Epoch 12----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.02107353335649697\n",
      "----------Epoch 13----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.020214096772647704\n",
      "----------Epoch 14----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.020238424084850194\n",
      "----------Epoch 15----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.018781335299508164\n",
      "----------Epoch 16----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.018240393595481963\n",
      "----------Epoch 17----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.018070918915927717\n",
      "----------Epoch 18----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01818790517449763\n",
      "----------Epoch 19----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01764034526902683\n",
      "----------Epoch 20----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.017506096996943055\n",
      "----------Epoch 21----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.018487664750902\n",
      "----------Epoch 22----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.017475951203749965\n",
      "----------Epoch 23----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.016812795571522\n",
      "----------Epoch 24----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.016672892652010333\n",
      "----------Epoch 25----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.016389657714471373\n",
      "----------Epoch 26----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01619575762420355\n",
      "----------Epoch 27----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.016093180174027215\n",
      "----------Epoch 28----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01605330826714635\n",
      "----------Epoch 29----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01593656941873895\n",
      "----------Epoch 30----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.016278701920792\n",
      "----------Epoch 31----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.016161028108530744\n",
      "----------Epoch 32----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.015835152166060257\n",
      "----------Epoch 33----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.015559933705197782\n",
      "----------Epoch 34----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01524348770143445\n",
      "----------Epoch 35----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01501308020069888\n",
      "----------Epoch 36----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014873706541244978\n",
      "----------Epoch 37----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01469733174794267\n",
      "----------Epoch 38----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014625330731637546\n",
      "----------Epoch 39----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014618363716284331\n",
      "----------Epoch 40----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01436674112895715\n",
      "----------Epoch 41----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014373268840892106\n",
      "----------Epoch 42----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014192977284090882\n",
      "----------Epoch 43----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014074172080523268\n",
      "----------Epoch 44----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014059902303228058\n",
      "----------Epoch 45----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014146969675268862\n",
      "----------Epoch 46----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013925976302359522\n",
      "----------Epoch 47----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.014070171437984736\n",
      "----------Epoch 48----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013743276213362967\n",
      "----------Epoch 49----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013683503203228423\n",
      "----------Epoch 50----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013591710866918577\n",
      "----------Epoch 51----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013516801044575333\n",
      "----------Epoch 52----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013513298251560515\n",
      "----------Epoch 53----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013476728178445519\n",
      "----------Epoch 54----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013439078198400201\n",
      "----------Epoch 55----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013514788552504224\n",
      "----------Epoch 56----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013543454303703819\n",
      "----------Epoch 57----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013541929030157242\n",
      "----------Epoch 58----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013653094402620011\n",
      "----------Epoch 59----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01327472599943351\n",
      "----------Epoch 60----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013106919721863473\n",
      "----------Epoch 61----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.013015543501920154\n",
      "----------Epoch 62----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012952396110871556\n",
      "----------Epoch 63----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012905867904731907\n",
      "----------Epoch 64----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01284055063049741\n",
      "----------Epoch 65----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01281195842017679\n",
      "----------Epoch 66----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012809057179934432\n",
      "----------Epoch 67----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.0127843273995617\n",
      "----------Epoch 68----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012812486158434264\n",
      "----------Epoch 69----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012783115391245055\n",
      "----------Epoch 70----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012761457657595118\n",
      "----------Epoch 71----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012770358468261883\n",
      "----------Epoch 72----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012688465041982145\n",
      "----------Epoch 73----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012723881513667629\n",
      "----------Epoch 74----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012609845130541121\n",
      "----------Epoch 75----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01256048366590643\n",
      "----------Epoch 76----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012566011634261645\n",
      "----------Epoch 77----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012559127705843793\n",
      "----------Epoch 78----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01252416312963385\n",
      "----------Epoch 79----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01248929580222316\n",
      "----------Epoch 80----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012505219461991615\n",
      "----------Epoch 81----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012480933125582091\n",
      "----------Epoch 82----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012413839173512822\n",
      "----------Epoch 83----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012415348674583528\n",
      "----------Epoch 84----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012383685778519235\n",
      "----------Epoch 85----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012394136842820295\n",
      "----------Epoch 86----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012358319986438783\n",
      "----------Epoch 87----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012303339346244778\n",
      "----------Epoch 88----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01228233533623369\n",
      "----------Epoch 89----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01226144216080993\n",
      "----------Epoch 90----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012239075263424479\n",
      "----------Epoch 91----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012236034211981082\n",
      "----------Epoch 92----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.0122431827680275\n",
      "----------Epoch 93----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012274104950603904\n",
      "----------Epoch 94----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012253240286132571\n",
      "----------Epoch 95----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012225451015089591\n",
      "----------Epoch 96----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012247438076883554\n",
      "----------Epoch 97----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012243665613176436\n",
      "----------Epoch 98----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01222463116318602\n",
      "----------Epoch 99----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.012181781289964607\n",
      "----------Epoch 100----------\n",
      "Iteration 0\n",
      "Iteration 100\n",
      "Train loss: 0.01218611313769421\n",
      "Time taken: 1102.052803516388\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train the neural bottleneck\n",
    "start = time.time()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralBottleneck()\n",
    "\n",
    "#MSE Loss as we are trying to compress and reconstruct the retinal vectors\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "avg_loss = run(model, criterion, optimiser, vectors, '7000_retinal_model', epochs=100)\n",
    "print(f'Time taken: {time.time()-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwO2M_g1TSQM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO/MOBxQRIjznzEiMzIisfS",
   "collapsed_sections": [],
   "name": "RetinaEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
